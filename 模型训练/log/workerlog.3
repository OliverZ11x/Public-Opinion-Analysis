[2023-04-13 22:24:36,051] [ WARNING] - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.
[2023-04-13 22:24:36,052] [    INFO] - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[2023-04-13 22:24:36,053] [    INFO] - ============================================================
[2023-04-13 22:24:36,053] [    INFO] -      Model Configuration Arguments      
[2023-04-13 22:24:36,053] [    INFO] - paddle commit id              :3fa7a736e32508e797616b6344d97814c37d3ff8
[2023-04-13 22:24:36,053] [    INFO] - export_model_dir              :./checkpoint/model_best
[2023-04-13 22:24:36,053] [    INFO] - export_type                   :paddle
[2023-04-13 22:24:36,053] [    INFO] - model_name_or_path            :utc-base
[2023-04-13 22:24:36,053] [    INFO] - 
[2023-04-13 22:24:36,053] [    INFO] - ============================================================
[2023-04-13 22:24:36,053] [    INFO] -       Data Configuration Arguments      
[2023-04-13 22:24:36,053] [    INFO] - paddle commit id              :3fa7a736e32508e797616b6344d97814c37d3ff8
[2023-04-13 22:24:36,053] [    INFO] - dataset_path                  :./data/
[2023-04-13 22:24:36,053] [    INFO] - dev_file                      :dev.txt
[2023-04-13 22:24:36,053] [    INFO] - single_label                  :False
[2023-04-13 22:24:36,054] [    INFO] - threshold                     :0.5
[2023-04-13 22:24:36,054] [    INFO] - train_file                    :train.txt
[2023-04-13 22:24:36,054] [    INFO] - 
[2023-04-13 22:24:36,054] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'utc-base'.
[2023-04-13 22:24:36,054] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/utc/utc_base_vocab.txt and saved to /home/aistudio/.paddlenlp/models/utc-base
[2023-04-13 22:24:36,195] [    INFO] - Found /home/aistudio/.paddlenlp/models/utc-base/utc_base_vocab.txt
[2023-04-13 22:24:36,220] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/utc-base/tokenizer_config.json
[2023-04-13 22:24:36,221] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/utc-base/special_tokens_map.json
[2023-04-13 22:24:36,222] [    INFO] - Model config ErnieConfig {
  "attention_probs_dropout_prob": 0.1,
  "enable_recompute": false,
  "fuse": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 2048,
  "model_type": "ernie",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "paddlenlp_version": null,
  "pool_act": "tanh",
  "task_id": 0,
  "task_type_vocab_size": 3,
  "type_vocab_size": 4,
  "use_task_id": false,
  "vocab_size": 39981
}

[2023-04-13 22:24:42,539] [    INFO] - Found /home/aistudio/.paddlenlp/models/utc-base/utc-base.pdparams
W0413 22:24:45.283370  1338 gpu_resources.cc:61] Please NOTE: device: 3, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0413 22:24:45.288010  1338 gpu_resources.cc:91] device: 3, cuDNN Version: 8.2.
[2023-04-13 22:24:46,191] [    INFO] - All model checkpoint weights were used when initializing UTC.

[2023-04-13 22:24:46,191] [    INFO] - All the weights of UTC were initialized from the model checkpoint at utc-base.
If your task is similar to the task the model of the checkpoint was trained on, you can already use UTC for predictions without further training.
[2023-04-13 22:24:46,192] [    INFO] - Assigning ['[O-MASK]'] to the additional_special_tokens key of the tokenizer
[2023-04-13 22:24:46,194] [ WARNING] - Skip 0 examples.
[2023-04-13 22:24:46,194] [ WARNING] - Skip 0 examples.
[2023-04-13 22:24:46,287] [    INFO] - ============================================================
[2023-04-13 22:24:46,287] [    INFO] -     Training Configuration Arguments    
[2023-04-13 22:24:46,287] [    INFO] - paddle commit id              :3fa7a736e32508e797616b6344d97814c37d3ff8
[2023-04-13 22:24:46,287] [    INFO] - _no_sync_in_gradient_accumulation:True
[2023-04-13 22:24:46,287] [    INFO] - adam_beta1                    :0.9
[2023-04-13 22:24:46,287] [    INFO] - adam_beta2                    :0.999
[2023-04-13 22:24:46,287] [    INFO] - adam_epsilon                  :1e-08
[2023-04-13 22:24:46,287] [    INFO] - alpha_rdrop                   :5.0
[2023-04-13 22:24:46,288] [    INFO] - alpha_rgl                     :0.5
[2023-04-13 22:24:46,288] [    INFO] - bf16                          :False
[2023-04-13 22:24:46,288] [    INFO] - bf16_full_eval                :False
[2023-04-13 22:24:46,288] [    INFO] - current_device                :gpu:3
[2023-04-13 22:24:46,288] [    INFO] - dataloader_drop_last          :False
[2023-04-13 22:24:46,288] [    INFO] - dataloader_num_workers        :0
[2023-04-13 22:24:46,288] [    INFO] - device                        :gpu
[2023-04-13 22:24:46,288] [    INFO] - disable_tqdm                  :True
[2023-04-13 22:24:46,288] [    INFO] - do_eval                       :True
[2023-04-13 22:24:46,288] [    INFO] - do_export                     :True
[2023-04-13 22:24:46,288] [    INFO] - do_predict                    :False
[2023-04-13 22:24:46,288] [    INFO] - do_train                      :True
[2023-04-13 22:24:46,288] [    INFO] - eval_batch_size               :2
[2023-04-13 22:24:46,288] [    INFO] - eval_steps                    :10
[2023-04-13 22:24:46,289] [    INFO] - evaluation_strategy           :IntervalStrategy.STEPS
[2023-04-13 22:24:46,289] [    INFO] - flatten_param_grads           :False
[2023-04-13 22:24:46,289] [    INFO] - fp16                          :False
[2023-04-13 22:24:46,289] [    INFO] - fp16_full_eval                :False
[2023-04-13 22:24:46,289] [    INFO] - fp16_opt_level                :O1
[2023-04-13 22:24:46,289] [    INFO] - freeze_dropout                :False
[2023-04-13 22:24:46,289] [    INFO] - freeze_plm                    :False
[2023-04-13 22:24:46,289] [    INFO] - gradient_accumulation_steps   :8
[2023-04-13 22:24:46,289] [    INFO] - greater_is_better             :True
[2023-04-13 22:24:46,289] [    INFO] - ignore_data_skip              :False
[2023-04-13 22:24:46,289] [    INFO] - label_names                   :None
[2023-04-13 22:24:46,289] [    INFO] - lazy_data_processing          :True
[2023-04-13 22:24:46,289] [    INFO] - learning_rate                 :1e-05
[2023-04-13 22:24:46,289] [    INFO] - load_best_model_at_end        :True
[2023-04-13 22:24:46,289] [    INFO] - local_process_index           :3
[2023-04-13 22:24:46,289] [    INFO] - local_rank                    :3
[2023-04-13 22:24:46,289] [    INFO] - log_level                     :-1
[2023-04-13 22:24:46,290] [    INFO] - log_level_replica             :-1
[2023-04-13 22:24:46,290] [    INFO] - log_on_each_node              :True
[2023-04-13 22:24:46,290] [    INFO] - logging_dir                   :./checkpoint/model_best/runs/Apr13_22-24-36_jupyter-691158-5951557
[2023-04-13 22:24:46,290] [    INFO] - logging_first_step            :False
[2023-04-13 22:24:46,290] [    INFO] - logging_steps                 :10
[2023-04-13 22:24:46,290] [    INFO] - logging_strategy              :IntervalStrategy.STEPS
[2023-04-13 22:24:46,290] [    INFO] - lr_scheduler_type             :SchedulerType.LINEAR
[2023-04-13 22:24:46,290] [    INFO] - max_grad_norm                 :1.0
[2023-04-13 22:24:46,290] [    INFO] - max_seq_length                :512
[2023-04-13 22:24:46,290] [    INFO] - max_steps                     :-1
[2023-04-13 22:24:46,290] [    INFO] - metric_for_best_model         :macro_f1
[2023-04-13 22:24:46,290] [    INFO] - minimum_eval_times            :None
[2023-04-13 22:24:46,290] [    INFO] - no_cuda                       :False
[2023-04-13 22:24:46,290] [    INFO] - num_train_epochs              :20.0
[2023-04-13 22:24:46,290] [    INFO] - optim                         :OptimizerNames.ADAMW
[2023-04-13 22:24:46,290] [    INFO] - output_dir                    :./checkpoint/model_best
[2023-04-13 22:24:46,290] [    INFO] - overwrite_output_dir          :True
[2023-04-13 22:24:46,290] [    INFO] - past_index                    :-1
[2023-04-13 22:24:46,291] [    INFO] - per_device_eval_batch_size    :2
[2023-04-13 22:24:46,291] [    INFO] - per_device_train_batch_size   :2
[2023-04-13 22:24:46,291] [    INFO] - ppt_adam_beta1                :0.9
[2023-04-13 22:24:46,291] [    INFO] - ppt_adam_beta2                :0.999
[2023-04-13 22:24:46,291] [    INFO] - ppt_adam_epsilon              :1e-08
[2023-04-13 22:24:46,291] [    INFO] - ppt_learning_rate             :0.0001
[2023-04-13 22:24:46,291] [    INFO] - ppt_weight_decay              :0.0
[2023-04-13 22:24:46,291] [    INFO] - prediction_loss_only          :False
[2023-04-13 22:24:46,291] [    INFO] - process_index                 :3
[2023-04-13 22:24:46,291] [    INFO] - recompute                     :False
[2023-04-13 22:24:46,291] [    INFO] - remove_unused_columns         :True
[2023-04-13 22:24:46,291] [    INFO] - report_to                     :['visualdl']
[2023-04-13 22:24:46,291] [    INFO] - resume_from_checkpoint        :None
[2023-04-13 22:24:46,291] [    INFO] - run_name                      :./checkpoint/model_best
[2023-04-13 22:24:46,291] [    INFO] - save_on_each_node             :False
[2023-04-13 22:24:46,291] [    INFO] - save_plm                      :False
[2023-04-13 22:24:46,291] [    INFO] - save_steps                    :10
[2023-04-13 22:24:46,292] [    INFO] - save_strategy                 :IntervalStrategy.STEPS
[2023-04-13 22:24:46,292] [    INFO] - save_total_limit              :1
[2023-04-13 22:24:46,292] [    INFO] - scale_loss                    :32768
[2023-04-13 22:24:46,292] [    INFO] - seed                          :1000
[2023-04-13 22:24:46,292] [    INFO] - sharding                      :[]
[2023-04-13 22:24:46,292] [    INFO] - sharding_degree               :-1
[2023-04-13 22:24:46,292] [    INFO] - should_log                    :False
[2023-04-13 22:24:46,292] [    INFO] - should_save                   :False
[2023-04-13 22:24:46,292] [    INFO] - skip_memory_metrics           :True
[2023-04-13 22:24:46,292] [    INFO] - train_batch_size              :2
[2023-04-13 22:24:46,292] [    INFO] - use_rdrop                     :False
[2023-04-13 22:24:46,292] [    INFO] - use_rgl                       :False
[2023-04-13 22:24:46,292] [    INFO] - warmup_ratio                  :0.0
[2023-04-13 22:24:46,292] [    INFO] - warmup_steps                  :0
[2023-04-13 22:24:46,292] [    INFO] - weight_decay                  :0.0
I0413 22:24:46.293216  1338 tcp_utils.cc:130] Successfully connected to 10.156.12.136:47351
[2023-04-13 22:24:47,240] [    INFO] - world_size                    :4
[2023-04-13 22:24:47,240] [    INFO] - 
[2023-04-13 22:24:47,269] [    INFO] - ***** Running training *****
[2023-04-13 22:24:47,269] [    INFO] -   Num examples = 45
[2023-04-13 22:24:47,269] [    INFO] -   Num Epochs = 20
[2023-04-13 22:24:47,269] [    INFO] -   Instantaneous batch size per device = 2
[2023-04-13 22:24:47,269] [    INFO] -   Total train batch size (w. parallel, distributed & accumulation) = 64
[2023-04-13 22:24:47,269] [    INFO] -   Gradient Accumulation steps = 8
[2023-04-13 22:24:47,270] [    INFO] -   Total optimization steps = 20.0
[2023-04-13 22:24:47,270] [    INFO] -   Total num train samples = 900.0
[2023-04-13 22:24:47,291] [    INFO] -   Number of trainable parameters = 118026368
[2023-04-13 22:24:50,555] [    INFO] - ***** Running Evaluation *****
[2023-04-13 22:24:50,555] [    INFO] -   Num examples = 6
[2023-04-13 22:24:50,556] [    INFO] -   Total prediction steps = 1
[2023-04-13 22:24:50,556] [    INFO] -   Pre device batch size = 2
[2023-04-13 22:24:50,556] [    INFO] -   Total Batch size = 8
[2023-04-13 22:25:01,428] [    INFO] - ***** Running Evaluation *****
[2023-04-13 22:25:01,429] [    INFO] -   Num examples = 6
[2023-04-13 22:25:01,430] [    INFO] -   Total prediction steps = 1
[2023-04-13 22:25:01,430] [    INFO] -   Pre device batch size = 2
[2023-04-13 22:25:01,430] [    INFO] -   Total Batch size = 8
[2023-04-13 22:25:01,466] [    INFO] - 
Training completed. 

[2023-04-13 22:25:04,258] [    INFO] - Loading best model from ./checkpoint/model_best/checkpoint-10 (score: 0.9504132231404958).
[2023-04-13 22:25:04,946] [    INFO] - Exporting inference model to ./checkpoint/model_best/model
[2023-04-13 22:25:16,470] [    INFO] - Inference model exported.
